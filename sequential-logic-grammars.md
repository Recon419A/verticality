# Sequential Logic Grammars 

Donald Bronson (Northwestern University)

## Abstract

Grammars are a time-proven technique for procedural content generation, but lack the modularity and flexibility required for modern procedural generation of start-to-finish structures. In this paper, we present a grammar-based technique for the generation of such structures efficiently at any scale, with applications to multi-researcher collaborations with limited information sharing and deployment of flexible and customizable prior work.

## Introduction

In the field of procedural content generation, grammars were one of the first and remain one of the most popular employed techniques. While grammars are exceptional at generating recursive structures from simple rules, they lack modularity and ease of customization; modifying a grammar slightly may produce drastically different results, and "black box" grammars are often difficult to build upon for further study.

To solve these problems, we lay forth the technique of sequential logic grammars, a modification of the grammar concept which introduces techniques from software development including modularity and composability. By breaking the generation process into multiple sequential layers and adding a filtering stage, we achieve dynamic runtime complexity and infinite customizability, prioritizing generated structures over ungenerated ones and putting forth a framework for the development of multi-researcher collaborations with zero contact: much as software developers have the option of simply importing libraries, we introduce the concept of modular "black box" grammars that can be used in a "plug and play" fashion not previously available.

At their simplest, sequential logic grammars consist of a series of layers, each of which has its own rules for generation and its own constraints, termed a *filter*. Traditionally, these layers consist of multiple related grammars; below, we unpack specifics and show the potential for arbitrary complexity and interweaving of multiple generation techniques to produce a scalable, deployable solution for professional development of procedural content.

## The Generate-Filter Algorithm

Sequential logic grammars rely on a process known as generate-and-filter to create each layer in the sequence. To create a layer, that layer is first generated according to its own rules, which produces its *base genotype*. This base genotype is then constrained by a function which takes the previous layers as input in order to produce a *constrained genotype*. In our implementation, the genotype format is multi-dimensional array of booleans; using such a format, pairwise mapping of logical operators such as AND, OR, and NOT to various combinations of the layers results in an appropriately constrained layer. It should be noted that layers may never look forwards - any constraining which takes place must rely exclusively on prior layers, and once a layer is laid, that layer is final.

### Genotypes and Phenotypes

We use the term *genotype* to refer to the logical structure of a layer, as opposed to the rendered representation of that layer, which we term a *phenotype* (borrowing language from the genetic algorithms literature). Our base genotypes are therefore logical representations of the structures they will eventually generate; in our experiments, this takes the form of an n-by-four array of booleans which we term *wing flags* (with n being the number of floors in a generated structure). The structures which are toggled on or off by the presence of a wing flag are termed *wings*, a term which initially was chosen for the spawning of literal wings but grew to include such things as doors, patios, stairs, and bridges. It is important in choosing a genotype representation to make sure that it is easily processable by the filtering step; as in genetic algorithms, it should be significantly simpler than the resultant phenotype, and the genotype-to-phenotype conversion process may take the form of any number of operations, even extending to its own procedural generation. As an example, consider the case of a recursive grammar; one can easily conceive of "wings" which consist of atriums that spawn their own wings in turn. It is important, however, that the genotype-to-phenotype transition runs no risk of interfering with any other genotype-to-phenotype transition; that is, there should be no possibility of a genotype being valid and the resultant phenotype being invalid due to collisions and overlapping. If such a level of complexity exists, it should be encoded in the generation process, not in the process of rendering; in fact, the ability to handle such complexity is a strength of sequential logic grammars, as we describe below.

### The Filter Step

A key strength of sequential logic grammars, when compared with traditional grammars, is the filter step. In a traditional grammar, the above example of "wings with wings" would require some means of encoding in the grammar that wings should not overlap; such a constraint would have to be fully expanded into a complex form and embedded in the grammar itself. In contrast, coding such a constraint with sequential logic grammars is as simple as generating wings and then checking that they do not collide with existing geometry. To illustrate this advantage, we will describe an implementation consisting of a variable number of layers; in fact, we will see that runtime-defined complexity is another strength of sequential logic grammars. To generate the "wings with wings" structure, we first spawn an atrium with simple wings consisting of a hallway ending in a room; this produces a structure vaguely in the shape of an addition symbol if all the wings are spawned in. Each spawned wing then adds its own layer to the generation process, in each of these layers (ranging from zero to four based on the number of wings generated), up to three wings are spawned from the terminal room. This generate step is simple enough, but it is the filter step that really allows for ease of implementation: rather than needing to specify non-colliding or non-overlapping structures in the generative grammar, we simply check each activated wing location to see if it overlaps with a previously generated structure; if it does, we turn it off and therefore never spawn it. In this way, structures of arbitrary complexity can be generated with no concern for the degree to which they overlap; the earlier-generated structure will always have priority and will "stunt" the growth of the later-spawned structure; there is zero risk of "bad geometry" produced by the intersection of two structures, and programming complexity is kept modular and used as needed by the program - no computation time is wasted on structures that do not spawn

## Logical Modularity and Dynamic Complexity at Runtime

### Logical Modularity

A key advantage of sequential grammars over other generation techniques is the modularity of their logic; an atrium that generates stairs, bridges, and wings knows how to generate those things itself; that atrium can then be used as the "wing" of another structure without duplication of those elements; in essence, it is a "black box" that knows how to generate atriums. This concept closely parallels object-oriented programming; just as objects have scope and can be redistributed as pre-packaged elements, so can elements in a sequential logic grammar. One researcher may develop a sequential logic grammar that spawns labyrinths; another may use that grammar in its pre-packaged form and build on top of it to generate levels by means of doors, keys, and puzzles - because the dependencies are all in a single direction, building on top of an existing generation tool is entirely additive, with no requirement of modifying the existing code. At the same time, objects may also be composed: a level designer may combine grammars designed to produce a boss lair, a dungeon, and a visually appealing "grand entrance" into a single grammar simply by including them as layers.

### Dynamic Complexity at Runtime

Because sequential grammars recurse by adding layers to the generation sequence, layers which would be added by an unspawned layer are precluded entirely from computation. In the running example, a "wing with wings" that fails to spawn its initial wing will never queue additional wings onto the stack, effectively short-cutting the computation whenever collisions occur.  More formally, the tree of possible generated structures will never be explored more than one layer beyond the final generated structure, since generated nodes are final. This means that structures created in this fashion scale with their *actual complexity*, not their *potential complexity*, which is an incredible boon to dense, complex, and overlapping structures that spawn small fractions of their possible superstructure.

## Sequential Completeness and Noninterference

When generating structures using a sequential logic grammar, it is important to note that the filter step may remove the constraints implied by a grammar. To consider the problem, first conceive of a multi-story four-walled structure in which we want both wings leading off each floor and stairs between all the floors. We can achieve this by creating two layers: the first, a layer which spawns wings along each of the four walls with a fifty percent chance; the second, a layer which spawns stairs along each of the four walls with a fifty percent chance. To apply these layers in sequence, we simply apply the filter constraint to the stairs layer which says "do not spawn stairs if there is already a wing along this wall." Now we begin to see the problem - if we do this, and our algorithm somehow produces a floor with four wings leading off of it, we find that we have left ourselves with no locations to place stairs. Thus, a grammar that is designed to generate between one and four sets of stairs may in fact generate none that survive the filtering step. To solve this conundrum, we introduce the concepts of *sequential completeness* and *noninterference*.

### Sequential Completeness

In a *sequentially complete* structure, each layer added causes the structure to appear complete, without reliance on future layers. In the above example, we could make our structure sequentially complete by changing the ordering of stairs and wings; if we generate the stairs first, our worst-case scenario structure is one with access to all four floors but no wings leading off of it. While such a structure is boring, it makes logical sense in a way that a structure with wings but no access between floors does not, since the entirety of our generated structure is reachable. Furthermore, the chance of generating a structure with no wings on any floor is significantly lower than the chance of generating a structure with no stairs on any *individual* floor - if one or two floors don't have wings, that's probably fine, but if one or two floors don't have stairs, that makes the entire rest of the structure inaccessible.

### Noninterference

Sequential completeness resolves the problem of incomplete structures, but it can sometimes make certain features dominant over others. In the above example, we might find that stairs are far more likely to spawn than wings, since there are fewer restrictions on where they can spawn. In certain cases, this can be fine, but in our example it is clear that wings are more interesting and detailed structures than stairs are - perhaps even with their own recursive sequential logic grammar - and we might decide we want to see more of them. In this case, we can make use of *noninterference*. When two layers are *noninterfering*, they don't overlap and don't constrain each other. To achieve this with our wings and stairs, we might decide to replace wall-hugging stairwells with corner-hugging spiral stairs, such that the spawn locations of wings and stairs no longer overlap. Then, it becomes clear that we can drop entirely the filter constraint on wings - and in doing so, we revert to the purest form of the grammar that defines them. In this way, constraints are kept to a minimum, and flexibility is maximized.

## Future Work

As with any newly-introduced technique, the applications for future work are incredibly numerous. To begin, we observe that our generate-and-filter algorithm lacks any form of back-tracking or constraint-solving; the addition of such tools might well pave the way for the next generation of hybrid procedural generation technologies. In addition, we note that the application for which we developed this technique - namely, generation of 3D structures - is but one of many, and interesting work remains to be done in applying the technique to other types of generation. Lastly, we point out that experimental verification of theoretical implications of the technique remains to be conducted - a survey of runtime and memory usage across a variety of tasks is non-trivial due to differences in the complexity of search spaces, but would indeed be worthwhile.

## Conclusion

Generated structures which make use of grammars have long suffered from the problem of being inflexible and difficult to effectively modify. The technique of sequential logic grammars introduces modularity and dynamic runtime complexity to the state of the art, creating space for researchers to build upon each other's work and develop in a fashion reliant upon inheritance and composition, techniques borrowed from the field of object-oriented programming. While the technique's full implications remain to be seen, early results in our own work are promising, and we look forward to seeing what other researchers do with the technology.
